{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import joblib\n",
    "\n",
    "def load_model(zielvariable):\n",
    "    if zielvariable == 'OptionTakeRate':\n",
    "        return tf.keras.models.load_model('models/deep_model18_tr.keras')\n",
    "    elif zielvariable == 'Bestätige Menge':\n",
    "        return tf.keras.models.load_model('models/deep_model18.keras')\n",
    "\n",
    "def get_data(merkmal, merkmalswert, startdatum):\n",
    "    dataset = pd.read_csv('data/MLbase_DataFrame.csv')\n",
    "    dataset['Datum'] = pd.to_datetime(dataset['Datum'])\n",
    "    startdatum = pd.to_datetime(startdatum)\n",
    "\n",
    "    # Filtere die letzten 12 Monate vor dem Startdatum\n",
    "    end_date = startdatum - pd.DateOffset(months=1)\n",
    "    start_date = end_date - pd.DateOffset(months=11)\n",
    "    if merkmalswert != \"Alle Merkmalswerte\":\n",
    "        data = dataset[(dataset['Merkmal'] == merkmal) & (dataset['Merkmalwert'] == merkmalswert) & (dataset['Datum'] >= start_date) & (dataset['Datum'] <= end_date)]\n",
    "    else:\n",
    "        data = dataset[(dataset['Merkmal'] == merkmal) & (dataset['Datum'] >= start_date) & (dataset['Datum'] <= end_date)]\n",
    "\n",
    "    print(\"Eingabedaten:\")\n",
    "    print(data.head())  # Diese Zeile druckt die ersten 5 Zeilen der Daten in die Konsole\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_preprocessors():\n",
    "    scaler_X = joblib.load('models/scaler_X.pkl')\n",
    "    scaler_y = joblib.load('models/scaler_y.pkl')\n",
    "    label_encoders = joblib.load('models/label_encoders.pkl')\n",
    "    return scaler_X, scaler_y, label_encoders\n",
    "\n",
    "def predict(merkmal, merkmalswert, startdatum, zielvariable):\n",
    "    # Anpassen des Zielvariablennamens\n",
    "    if zielvariable == 'BestätigteMenge':\n",
    "        zielvariable = 'Bestätige Menge'\n",
    "\n",
    "    model = load_model(zielvariable)\n",
    "    data = get_data(merkmal, merkmalswert, startdatum)\n",
    "    \n",
    "    # Überprüfen, ob genügend Daten vorhanden sind\n",
    "    if len(data) < 12:\n",
    "        raise ValueError(\"Nicht genügend Daten für die Vorhersage vorhanden.\")\n",
    "    \n",
    "    # Definiere die kontinuierlichen und kategorischen Merkmale\n",
    "    continuous_features = ['Monat_sin', 'Monat_cos', 'USTR10Y', 'WeizenSpot', 'CornSpot', 'GER10Y', 'WtiOilSpot', 'SoySpot', 'AgriSpot']\n",
    "    categorical_features = ['Merkmal', 'Merkmalwert']\n",
    "\n",
    "    # Überprüfe, ob alle kontinuierlichen Merkmale in den Daten vorhanden sind\n",
    "    if not all(feature in data.columns for feature in continuous_features + ['Jahr']):\n",
    "        raise ValueError(\"Nicht alle kontinuierlichen Merkmale sind in den Daten vorhanden.\")\n",
    "    \n",
    "    X_cont = data[continuous_features].values\n",
    "    jahr = data['Jahr'].values.reshape(-1, 1)\n",
    "\n",
    "    # Laden der gespeicherten Scaler und Encoder\n",
    "    scaler_X, scaler_y, label_encoders = load_preprocessors()\n",
    "    X_cont_scaled = scaler_X.transform(X_cont)\n",
    "    \n",
    "    # Kombiniere die skalierten kontinuierlichen Merkmale und die Jahr-Spalte\n",
    "    X_cont_combined = np.hstack([jahr, X_cont_scaled])\n",
    "    \n",
    "    # Kodieren der kategorischen Merkmale\n",
    "    X_cat_encoded = []\n",
    "    for feature in categorical_features:\n",
    "        encoder = label_encoders[feature]\n",
    "        encoded_values = encoder.transform(data[feature].values)\n",
    "        X_cat_encoded.append(encoded_values)\n",
    "    X_cat_encoded = np.array(X_cat_encoded).T\n",
    "\n",
    "    # Eingabeform für das Modell erstellen\n",
    "    X_cont_combined = X_cont_combined.reshape(1, 12, len(continuous_features) + 1)\n",
    "    X_cat_encoded = X_cat_encoded.reshape(1, 12, len(categorical_features))\n",
    "\n",
    "    # Vorhersage erstellen\n",
    "    predictions = model.predict([X_cont_combined] + [X_cat_encoded[:, :, i] for i in range(X_cat_encoded.shape[2])])\n",
    "    predictions_rescaled = scaler_y.inverse_transform(predictions.reshape(-1, 12))\n",
    "    predictions_rescaled = np.round(predictions_rescaled)\n",
    "\n",
    "    \n",
    "    return predictions_rescaled\n",
    "\n",
    "\n",
    "def predict_all(merkmal, startdatum, zielvariable):\n",
    "    # Anpassen des Zielvariablennamens\n",
    "    if zielvariable == 'BestätigteMenge':\n",
    "        zielvariable = 'Bestätige Menge'\n",
    "\n",
    "    model = load_model(zielvariable)\n",
    "    data = get_data(merkmal, \"Alle Merkmalswerte\", startdatum)\n",
    "    \n",
    "    # Überprüfen, ob genügend Daten vorhanden sind\n",
    "    if len(data) < 12:\n",
    "        raise ValueError(\"Nicht genügend Daten für die Vorhersage vorhanden.\")\n",
    "    \n",
    "    # Definiere die kontinuierlichen und kategorischen Merkmale\n",
    "    continuous_features = ['Monat_sin', 'Monat_cos', 'USTR10Y', 'WeizenSpot', 'CornSpot', 'GER10Y', 'WtiOilSpot', 'SoySpot', 'AgriSpot']\n",
    "    categorical_features = ['Merkmal', 'Merkmalwert']\n",
    "    \n",
    "    # Überprüfe, ob alle kontinuierlichen Merkmale in den Daten vorhanden sind\n",
    "    if not all(feature in data.columns for feature in continuous_features):\n",
    "        raise ValueError(\"Nicht alle kontinuierlichen Merkmale sind in den Daten vorhanden.\")\n",
    "    \n",
    "    X_cont = data[continuous_features].values\n",
    "    X_cat = data[categorical_features].values\n",
    "\n",
    "    # Laden der gespeicherten Scaler und Encoder\n",
    "    scaler_X, scaler_y, label_encoders = load_preprocessors()\n",
    "    X_cont = scaler_X.transform(X_cont)\n",
    "    \n",
    "    # Kodieren der kategorischen Merkmale\n",
    "    X_cat_encoded = []\n",
    "    for feature in categorical_features:\n",
    "        encoder = label_encoders[feature]\n",
    "        encoded_values = encoder.transform(data[feature].values)\n",
    "        X_cat_encoded.append(encoded_values)\n",
    "    X_cat_encoded = np.array(X_cat_encoded).T\n",
    "   \n",
    "\n",
    "    # Eingabeform für das Modell erstellen\n",
    "    X_cont = X_cont.reshape(1, 12, len(continuous_features))\n",
    "    X_cat_encoded = X_cat_encoded.reshape(1, 12, len(categorical_features))\n",
    "\n",
    "    predictions = model.predict([X_cont] + [X_cat_encoded[:, :, i] for i in range(X_cat_encoded.shape[2])])\n",
    "    \n",
    "    # Rücktransformation der Vorhersage\n",
    "    predictions_rescaled = scaler_y.inverse_transform(predictions.reshape(-1, 12))\n",
    "   \n",
    "    \n",
    "    # Erstellung des DataFrame für alle Merkmalswerte\n",
    "    result_df = pd.DataFrame(predictions_rescaled, columns=[f'Vorhersage_{i+1}' for i in range(12)])\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=models/deep_model18.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m startdatum \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2021-03-01\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m zielvariable \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBestätigteMenge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerkmal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerkmalswert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstartdatum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzielvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 42\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(merkmal, merkmalswert, startdatum, zielvariable)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m zielvariable \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBestätigteMenge\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     40\u001b[0m     zielvariable \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBestätige Menge\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzielvariable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m data \u001b[38;5;241m=\u001b[39m get_data(merkmal, merkmalswert, startdatum)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Überprüfen, ob genügend Daten vorhanden sind\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(zielvariable)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/deep_model18_tr.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m zielvariable \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBestätige Menge\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/deep_model18.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:185\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(filepath)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: filepath=models/deep_model18.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "merkmal = \"N08\"\n",
    "merkmalswert = \"N08-0960\"\n",
    "startdatum = \"2021-03-01\"\n",
    "zielvariable = \"BestätigteMenge\"\n",
    "predict(merkmal, merkmalswert, startdatum, zielvariable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
